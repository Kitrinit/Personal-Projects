{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0402af91-faec-4ed0-9244-27671d2c2b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "080048ea-0965-46d2-917c-720ab7a902f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc1d49b0-5122-44bb-9fca-e92c43f12340",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_jobstreet():\n",
    "    scrape_start_time = datetime.now()\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://ph.jobstreet.com/Data-Science-jobs?sortmode=ListedDate\")\n",
    "\n",
    "        print(\"üîç Waiting for job listings to load...\")\n",
    "        await page.wait_for_selector(\"article[data-testid='job-card']\")\n",
    "        await asyncio.sleep(5)  # Ensure full DOM is loaded\n",
    "\n",
    "        jobs = await page.query_selector_all(\"article[data-testid='job-card']\")\n",
    "        print(f\"üìÑ Found {len(jobs)} job listings\")\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for i, job in enumerate(jobs):\n",
    "            try:\n",
    "                print(f\"üëâ Clicking job {i+1}...\")\n",
    "                await job.click()\n",
    "                await asyncio.sleep(2)  # Let right panel populate\n",
    "\n",
    "                # Wait for key detail to appear\n",
    "                await page.wait_for_selector(\"div[data-automation='jobAdDetails']\", timeout=5000)\n",
    "\n",
    "                # Extract job details\n",
    "                job_title_el = await page.query_selector(\"h1[data-automation='job-detail-title']\")\n",
    "                job_title = await job_title_el.inner_text() if job_title_el else \"N/A\"\n",
    "\n",
    "                company_el = await page.query_selector(\"span[data-automation='advertiser-name']\")\n",
    "                company = await company_el.inner_text() if company_el else \"N/A\"\n",
    "\n",
    "                location_el = await page.query_selector(\"span[data-automation='job-detail-location']\")\n",
    "                location = await location_el.inner_text() if location_el else \"N/A\"\n",
    "\n",
    "                work_type_el = await page.query_selector(\"span[data-automation='job-detail-work-type']\")\n",
    "                work_type = await work_type_el.inner_text() if work_type_el else \"N/A\"\n",
    "\n",
    "                classification_el = await page.query_selector(\"span[data-automation='job-detail-classifications']\")\n",
    "                classification = await classification_el.inner_text() if classification_el else \"N/A\"\n",
    "\n",
    "                # Salary: check which one exists\n",
    "                salary_el = await page.query_selector(\"span[data-automation='job-detail-salary']\")\n",
    "                if salary_el:\n",
    "                    salary = await salary_el.inner_text()\n",
    "                else:\n",
    "                    salary = \"\"\n",
    "\n",
    "                # Description block\n",
    "                desc_el = await page.query_selector(\"div[data-automation='jobAdDetails']\")\n",
    "                job_description = await desc_el.inner_text() if desc_el else \"N/A\"\n",
    "\n",
    "                # Job URL from job card element\n",
    "                anchor = await job.query_selector(\"a[data-automation='job-list-view-job-link']\")\n",
    "                url_suffix = await anchor.get_attribute(\"href\") if anchor else \"\"\n",
    "                job_url = \"https://ph.jobstreet.com\" + url_suffix if url_suffix else \"N/A\"\n",
    "\n",
    "                # Posted time from job card\n",
    "                posted_el = await job.query_selector(\"span[data-automation='jobListingDate']\")\n",
    "                posted_raw = await posted_el.inner_text() if posted_el else \"\"\n",
    "                posted_datetime = \"N/A\"\n",
    "                try:\n",
    "                    if \"m\" in posted_raw:\n",
    "                        minutes = int(posted_raw.split(\"m\")[0].strip())\n",
    "                        posted_time = scrape_start_time - timedelta(minutes=minutes)\n",
    "                    elif \"hr\" in posted_raw:\n",
    "                        hours = int(posted_raw.split(\"hr\")[0].strip())\n",
    "                        posted_time = scrape_start_time - timedelta(hours=hours)\n",
    "                    elif \"d\" in posted_raw:\n",
    "                        days = int(posted_raw.split(\"d\")[0].strip())\n",
    "                        posted_time = scrape_start_time - timedelta(days=days)\n",
    "                    else:\n",
    "                        posted_time = scrape_start_time\n",
    "                    posted_datetime = posted_time.strftime(\"%d/%m/%y %H:%M\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to parse posted time '{posted_raw}': {e}\")\n",
    "\n",
    "                data.append({\n",
    "                    \"Job Title\": job_title,\n",
    "                    \"Company\": company,\n",
    "                    \"Location\": location,\n",
    "                    \"Work Type\": work_type,\n",
    "                    \"Classification\": classification,\n",
    "                    \"Salary\": salary,\n",
    "                    \"Job Description\": job_description,\n",
    "                    \"Job URL\": job_url,\n",
    "                    \"Posted Time\": posted_datetime\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error on job {i+1}: {e}\")\n",
    "                continue\n",
    "\n",
    "        await browser.close()\n",
    "        return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8566f40-aaf1-403f-9416-6e40a9f4eb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Waiting for job listings to load...\n",
      "üìÑ Found 32 job listings\n",
      "üëâ Clicking job 1...\n",
      "üëâ Clicking job 2...\n",
      "üëâ Clicking job 3...\n",
      "üëâ Clicking job 4...\n",
      "üëâ Clicking job 5...\n",
      "üëâ Clicking job 6...\n",
      "üëâ Clicking job 7...\n",
      "üëâ Clicking job 8...\n",
      "üëâ Clicking job 9...\n",
      "üëâ Clicking job 10...\n",
      "üëâ Clicking job 11...\n",
      "üëâ Clicking job 12...\n",
      "üëâ Clicking job 13...\n",
      "üëâ Clicking job 14...\n",
      "üëâ Clicking job 15...\n",
      "üëâ Clicking job 16...\n",
      "üëâ Clicking job 17...\n",
      "üëâ Clicking job 18...\n",
      "üëâ Clicking job 19...\n",
      "üëâ Clicking job 20...\n",
      "üëâ Clicking job 21...\n",
      "üëâ Clicking job 22...\n",
      "üëâ Clicking job 23...\n",
      "üëâ Clicking job 24...\n",
      "üëâ Clicking job 25...\n",
      "üëâ Clicking job 26...\n",
      "üëâ Clicking job 27...\n",
      "üëâ Clicking job 28...\n",
      "üëâ Clicking job 29...\n",
      "üëâ Clicking job 30...\n",
      "üëâ Clicking job 31...\n",
      "üëâ Clicking job 32...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job URL</th>\n",
       "      <th>Posted Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Integration Specialist</td>\n",
       "      <td>MegaXcess IT Solutions Inc.</td>\n",
       "      <td>Pasig City, Metro Manila (Hybrid)</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Business/Systems Analysts (Information &amp; Commu...</td>\n",
       "      <td></td>\n",
       "      <td>THE OPPORTUNITY:\\n\\nThe Integration Management...</td>\n",
       "      <td>https://ph.jobstreet.com/job/85863081?type=sta...</td>\n",
       "      <td>18/07/25 14:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dev Engineer</td>\n",
       "      <td>OwnBank</td>\n",
       "      <td>Bonifacio Global City, Taguig City, Metro Manila</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Developers/Programmers (Information &amp; Communic...</td>\n",
       "      <td>‚Ç±80,000 ‚Äì ‚Ç±120,000 per month</td>\n",
       "      <td>Duties and Responsibilities\\n\\nOversee end-to-...</td>\n",
       "      <td>https://ph.jobstreet.com/job/85863682?type=sta...</td>\n",
       "      <td>18/07/25 14:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Network Engineer</td>\n",
       "      <td>Compass Offices</td>\n",
       "      <td>Taguig City, Metro Manila</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Networks &amp; Systems Administration (Information...</td>\n",
       "      <td></td>\n",
       "      <td>The Network Engineer will be responsible for i...</td>\n",
       "      <td>https://ph.jobstreet.com/job/85863305?type=sta...</td>\n",
       "      <td>18/07/25 14:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jr. SAP Manager</td>\n",
       "      <td>Benby Enterprises, Inc.</td>\n",
       "      <td>Quezon City, Metro Manila</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Management (Information &amp; Communication Techno...</td>\n",
       "      <td></td>\n",
       "      <td>SAP Jr. Manager is responsible in the followin...</td>\n",
       "      <td>https://ph.jobstreet.com/job/85862918?type=sta...</td>\n",
       "      <td>18/07/25 14:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Software Development Lead</td>\n",
       "      <td>Benby Enterprises, Inc.</td>\n",
       "      <td>Quezon City, Metro Manila</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Team Leaders (Information &amp; Communication Tech...</td>\n",
       "      <td></td>\n",
       "      <td>Key Responsibilities:\\n\\nLead and manage all p...</td>\n",
       "      <td>https://ph.jobstreet.com/job/85862630?type=sta...</td>\n",
       "      <td>18/07/25 14:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Job Title                       Company  \\\n",
       "0         Integration Specialist  MegaXcess IT Solutions Inc.    \n",
       "1                   Dev Engineer                      OwnBank    \n",
       "2               Network Engineer              Compass Offices    \n",
       "3                Jr. SAP Manager      Benby Enterprises, Inc.    \n",
       "4  Sr. Software Development Lead      Benby Enterprises, Inc.    \n",
       "\n",
       "                                           Location  Work Type  \\\n",
       "0                 Pasig City, Metro Manila (Hybrid)  Full time   \n",
       "1  Bonifacio Global City, Taguig City, Metro Manila  Full time   \n",
       "2                         Taguig City, Metro Manila  Full time   \n",
       "3                         Quezon City, Metro Manila  Full time   \n",
       "4                         Quezon City, Metro Manila  Full time   \n",
       "\n",
       "                                      Classification  \\\n",
       "0  Business/Systems Analysts (Information & Commu...   \n",
       "1  Developers/Programmers (Information & Communic...   \n",
       "2  Networks & Systems Administration (Information...   \n",
       "3  Management (Information & Communication Techno...   \n",
       "4  Team Leaders (Information & Communication Tech...   \n",
       "\n",
       "                         Salary  \\\n",
       "0                                 \n",
       "1  ‚Ç±80,000 ‚Äì ‚Ç±120,000 per month   \n",
       "2                                 \n",
       "3                                 \n",
       "4                                 \n",
       "\n",
       "                                     Job Description  \\\n",
       "0  THE OPPORTUNITY:\\n\\nThe Integration Management...   \n",
       "1  Duties and Responsibilities\\n\\nOversee end-to-...   \n",
       "2  The Network Engineer will be responsible for i...   \n",
       "3  SAP Jr. Manager is responsible in the followin...   \n",
       "4  Key Responsibilities:\\n\\nLead and manage all p...   \n",
       "\n",
       "                                             Job URL     Posted Time  \n",
       "0  https://ph.jobstreet.com/job/85863081?type=sta...  18/07/25 14:43  \n",
       "1  https://ph.jobstreet.com/job/85863682?type=sta...  18/07/25 14:41  \n",
       "2  https://ph.jobstreet.com/job/85863305?type=sta...  18/07/25 14:34  \n",
       "3  https://ph.jobstreet.com/job/85862918?type=sta...  18/07/25 14:27  \n",
       "4  https://ph.jobstreet.com/job/85862630?type=sta...  18/07/25 14:21  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the async function inside Jupyter\n",
    "df = await scrape_jobstreet()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb14d5c8-9088-4793-a2aa-9d58d82bddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"../../Projects-Data/Job-Scraping/Data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97173ddf-6915-430b-b0c0-38641ed60189",
   "metadata": {},
   "source": [
    "# Testing Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4417597-53df-4228-b69a-68dc032803aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from playwright.async_api import async_playwright\n",
    "import os\n",
    "import re\n",
    "\n",
    "async def scrape_jobstreet():\n",
    "    scrape_start_time = datetime.now()\n",
    "    file_path = \"../../Projects-Data/Job-Scraping/Data.xlsx\"\n",
    "\n",
    "    # Load existing data or initialize empty DataFrame\n",
    "    if os.path.exists(file_path):\n",
    "        existing_df = pd.read_excel(file_path)\n",
    "        existing_ids = set(existing_df[\"Job ID\"].dropna().astype(str).unique())\n",
    "    else:\n",
    "        existing_df = pd.DataFrame(columns=[\n",
    "            \"Job Title\", \"Company\", \"Location\", \"Work Type\", \"Classification\",\n",
    "            \"Salary\", \"Job Description\", \"Job ID\", \"Posted Time\"\n",
    "        ])\n",
    "        existing_ids = set()\n",
    "\n",
    "    new_data = []\n",
    "    page_num = 1\n",
    "    stop_scraping = False\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "        page = await browser.new_page()\n",
    "\n",
    "        while not stop_scraping:\n",
    "            url = f\"https://ph.jobstreet.com/Data-Science-jobs?page={page_num}&sortmode=ListedDate\"\n",
    "            print(f\"\\nüåê Navigating to Page {page_num} ‚Äî {url}\")\n",
    "            await page.goto(url)\n",
    "            await page.wait_for_selector(\"article[data-testid='job-card']\")\n",
    "            await asyncio.sleep(3)\n",
    "\n",
    "            jobs = await page.query_selector_all(\"article[data-testid='job-card']\")\n",
    "            print(f\"üìÑ Found {len(jobs)} job listings on page {page_num}\")\n",
    "\n",
    "            for i, job in enumerate(jobs):\n",
    "                try:\n",
    "                    print(f\"üëâ Clicking job {i+1} on page {page_num}...\")\n",
    "                    await job.click()\n",
    "                    await asyncio.sleep(2)\n",
    "                    await page.wait_for_selector(\"div[data-automation='jobAdDetails']\", timeout=10000)\n",
    "\n",
    "                    # Extract Job ID from href\n",
    "                    anchor = await job.query_selector(\"a[data-automation='job-list-view-job-link']\")\n",
    "                    url_suffix = await anchor.get_attribute(\"href\") if anchor else \"\"\n",
    "                    match = re.search(r\"/job/(\\d+)\", url_suffix)\n",
    "                    job_id = match.group(1) if match else \"N/A\"\n",
    "\n",
    "                    # üö® Stop if duplicate\n",
    "                    if job_id in existing_ids:\n",
    "                        print(f\"üõë Duplicate job ID '{job_id}' found ‚Äî stopping.\")\n",
    "                        stop_scraping = True\n",
    "                        break\n",
    "\n",
    "                    # Extract other details\n",
    "                    job_title_el = await page.query_selector(\"h1[data-automation='job-detail-title']\")\n",
    "                    job_title = await job_title_el.inner_text() if job_title_el else \"N/A\"\n",
    "\n",
    "                    company_el = await page.query_selector(\"span[data-automation='advertiser-name']\")\n",
    "                    company = await company_el.inner_text() if company_el else \"N/A\"\n",
    "\n",
    "                    location_el = await page.query_selector(\"span[data-automation='job-detail-location']\")\n",
    "                    location = await location_el.inner_text() if location_el else \"N/A\"\n",
    "\n",
    "                    work_type_el = await page.query_selector(\"span[data-automation='job-detail-work-type']\")\n",
    "                    work_type = await work_type_el.inner_text() if work_type_el else \"N/A\"\n",
    "\n",
    "                    classification_el = await page.query_selector(\"span[data-automation='job-detail-classifications']\")\n",
    "                    classification = await classification_el.inner_text() if classification_el else \"N/A\"\n",
    "\n",
    "                    salary_el = await page.query_selector(\"span[data-automation='job-detail-salary']\")\n",
    "                    salary = await salary_el.inner_text() if salary_el else \"\"\n",
    "\n",
    "                    desc_el = await page.query_selector(\"div[data-automation='jobAdDetails']\")\n",
    "                    job_description = await desc_el.inner_text() if desc_el else \"N/A\"\n",
    "\n",
    "                    posted_el = await job.query_selector(\"span[data-automation='jobListingDate']\")\n",
    "                    posted_raw = await posted_el.inner_text() if posted_el else \"\"\n",
    "                    posted_datetime = \"N/A\"\n",
    "                    try:\n",
    "                        if \"m\" in posted_raw:\n",
    "                            minutes = int(posted_raw.split(\"m\")[0].strip())\n",
    "                            posted_time = scrape_start_time - timedelta(minutes=minutes)\n",
    "                        elif \"hr\" in posted_raw:\n",
    "                            hours = int(posted_raw.split(\"hr\")[0].strip())\n",
    "                            posted_time = scrape_start_time - timedelta(hours=hours)\n",
    "                        elif \"d\" in posted_raw:\n",
    "                            days = int(posted_raw.split(\"d\")[0].strip())\n",
    "                            posted_time = scrape_start_time - timedelta(days=days)\n",
    "                        else:\n",
    "                            posted_time = scrape_start_time\n",
    "                        posted_datetime = posted_time.strftime(\"%d/%m/%y %H:%M\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ö†Ô∏è Failed to parse posted time '{posted_raw}': {e}\")\n",
    "\n",
    "                    new_data.append({\n",
    "                        \"Job Title\": job_title,\n",
    "                        \"Company\": company,\n",
    "                        \"Location\": location,\n",
    "                        \"Work Type\": work_type,\n",
    "                        \"Classification\": classification,\n",
    "                        \"Salary\": salary,\n",
    "                        \"Job Description\": job_description,\n",
    "                        \"Job ID\": job_id,\n",
    "                        \"Posted Time\": posted_datetime\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error on job {i+1} of page {page_num}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            page_num += 1\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "    # Save to file if there are new jobs\n",
    "    if new_data:\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "        full_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "        full_df.to_excel(file_path, index=False)\n",
    "        print(f\"\\n‚úÖ Scraping finished. {len(new_data)} new job(s) saved to Excel.\")\n",
    "    else:\n",
    "        print(\"\\nüìÇ No new jobs found to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d44c5a0-82e2-4b41-963b-342e161c37c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåê Navigating to Page 1 ‚Äî https://ph.jobstreet.com/Data-Science-jobs?page=1&sortmode=ListedDate\n",
      "üìÑ Found 32 job listings on page 1\n",
      "üëâ Clicking job 1 on page 1...\n",
      "üëâ Clicking job 2 on page 1...\n",
      "üëâ Clicking job 3 on page 1...\n",
      "üëâ Clicking job 4 on page 1...\n",
      "üëâ Clicking job 5 on page 1...\n",
      "üëâ Clicking job 6 on page 1...\n",
      "üëâ Clicking job 7 on page 1...\n",
      "üëâ Clicking job 8 on page 1...\n",
      "üëâ Clicking job 9 on page 1...\n",
      "üëâ Clicking job 10 on page 1...\n",
      "üëâ Clicking job 11 on page 1...\n",
      "üëâ Clicking job 12 on page 1...\n",
      "üëâ Clicking job 13 on page 1...\n",
      "üëâ Clicking job 14 on page 1...\n",
      "üëâ Clicking job 15 on page 1...\n",
      "üëâ Clicking job 16 on page 1...\n",
      "üëâ Clicking job 17 on page 1...\n",
      "üëâ Clicking job 18 on page 1...\n",
      "üëâ Clicking job 19 on page 1...\n",
      "üëâ Clicking job 20 on page 1...\n",
      "üëâ Clicking job 21 on page 1...\n",
      "üëâ Clicking job 22 on page 1...\n",
      "üëâ Clicking job 23 on page 1...\n",
      "üëâ Clicking job 24 on page 1...\n",
      "üëâ Clicking job 25 on page 1...\n",
      "üëâ Clicking job 26 on page 1...\n",
      "üëâ Clicking job 27 on page 1...\n",
      "üëâ Clicking job 28 on page 1...\n",
      "üëâ Clicking job 29 on page 1...\n",
      "üëâ Clicking job 30 on page 1...\n",
      "üëâ Clicking job 31 on page 1...\n",
      "üëâ Clicking job 32 on page 1...\n",
      "\n",
      "üåê Navigating to Page 2 ‚Äî https://ph.jobstreet.com/Data-Science-jobs?page=2&sortmode=ListedDate\n",
      "üìÑ Found 32 job listings on page 2\n",
      "üëâ Clicking job 1 on page 2...\n",
      "üëâ Clicking job 2 on page 2...\n",
      "üëâ Clicking job 3 on page 2...\n",
      "üëâ Clicking job 4 on page 2...\n",
      "üëâ Clicking job 5 on page 2...\n",
      "üëâ Clicking job 6 on page 2...\n",
      "üëâ Clicking job 7 on page 2...\n",
      "üëâ Clicking job 8 on page 2...\n",
      "üëâ Clicking job 9 on page 2...\n",
      "üëâ Clicking job 10 on page 2...\n",
      "üëâ Clicking job 11 on page 2...\n",
      "üëâ Clicking job 12 on page 2...\n",
      "üëâ Clicking job 13 on page 2...\n",
      "üëâ Clicking job 14 on page 2...\n",
      "üëâ Clicking job 15 on page 2...\n",
      "üëâ Clicking job 16 on page 2...\n",
      "üëâ Clicking job 17 on page 2...\n",
      "üëâ Clicking job 18 on page 2...\n",
      "üëâ Clicking job 19 on page 2...\n",
      "üëâ Clicking job 20 on page 2...\n",
      "üëâ Clicking job 21 on page 2...\n",
      "üëâ Clicking job 22 on page 2...\n",
      "üëâ Clicking job 23 on page 2...\n",
      "üëâ Clicking job 24 on page 2...\n",
      "üëâ Clicking job 25 on page 2...\n",
      "üëâ Clicking job 26 on page 2...\n",
      "üëâ Clicking job 27 on page 2...\n",
      "üëâ Clicking job 28 on page 2...\n",
      "üëâ Clicking job 29 on page 2...\n",
      "üëâ Clicking job 30 on page 2...\n",
      "üëâ Clicking job 31 on page 2...\n",
      "üëâ Clicking job 32 on page 2...\n",
      "\n",
      "üåê Navigating to Page 3 ‚Äî https://ph.jobstreet.com/Data-Science-jobs?page=3&sortmode=ListedDate\n",
      "üìÑ Found 32 job listings on page 3\n",
      "üëâ Clicking job 1 on page 3...\n",
      "üëâ Clicking job 2 on page 3...\n",
      "üëâ Clicking job 3 on page 3...\n",
      "üëâ Clicking job 4 on page 3...\n",
      "üëâ Clicking job 5 on page 3...\n",
      "üëâ Clicking job 6 on page 3...\n",
      "üëâ Clicking job 7 on page 3...\n",
      "üëâ Clicking job 8 on page 3...\n",
      "üëâ Clicking job 9 on page 3...\n",
      "üëâ Clicking job 10 on page 3...\n",
      "üëâ Clicking job 11 on page 3...\n",
      "üëâ Clicking job 12 on page 3...\n",
      "üëâ Clicking job 13 on page 3...\n",
      "üëâ Clicking job 14 on page 3...\n",
      "üëâ Clicking job 15 on page 3...\n",
      "üëâ Clicking job 16 on page 3...\n",
      "üëâ Clicking job 17 on page 3...\n",
      "üëâ Clicking job 18 on page 3...\n",
      "üëâ Clicking job 19 on page 3...\n",
      "üëâ Clicking job 20 on page 3...\n",
      "üëâ Clicking job 21 on page 3...\n",
      "üëâ Clicking job 22 on page 3...\n",
      "üëâ Clicking job 23 on page 3...\n",
      "üëâ Clicking job 24 on page 3...\n",
      "üëâ Clicking job 25 on page 3...\n",
      "üëâ Clicking job 26 on page 3...\n",
      "üëâ Clicking job 27 on page 3...\n",
      "üëâ Clicking job 28 on page 3...\n",
      "üëâ Clicking job 29 on page 3...\n",
      "üëâ Clicking job 30 on page 3...\n",
      "üëâ Clicking job 31 on page 3...\n",
      "üëâ Clicking job 32 on page 3...\n",
      "\n",
      "üåê Navigating to Page 4 ‚Äî https://ph.jobstreet.com/Data-Science-jobs?page=4&sortmode=ListedDate\n",
      "üìÑ Found 32 job listings on page 4\n",
      "üëâ Clicking job 1 on page 4...\n",
      "üëâ Clicking job 2 on page 4...\n",
      "üëâ Clicking job 3 on page 4...\n",
      "üëâ Clicking job 4 on page 4...\n",
      "üëâ Clicking job 5 on page 4...\n",
      "üëâ Clicking job 6 on page 4...\n",
      "üëâ Clicking job 7 on page 4...\n",
      "üëâ Clicking job 8 on page 4...\n",
      "üëâ Clicking job 9 on page 4...\n",
      "üëâ Clicking job 10 on page 4...\n",
      "üëâ Clicking job 11 on page 4...\n",
      "üëâ Clicking job 12 on page 4...\n",
      "üëâ Clicking job 13 on page 4...\n",
      "üëâ Clicking job 14 on page 4...\n",
      "üëâ Clicking job 15 on page 4...\n",
      "üëâ Clicking job 16 on page 4...\n",
      "üëâ Clicking job 17 on page 4...\n",
      "üëâ Clicking job 18 on page 4...\n",
      "üëâ Clicking job 19 on page 4...\n",
      "üëâ Clicking job 20 on page 4...\n",
      "üëâ Clicking job 21 on page 4...\n",
      "üëâ Clicking job 22 on page 4...\n",
      "üëâ Clicking job 23 on page 4...\n",
      "üëâ Clicking job 24 on page 4...\n",
      "üëâ Clicking job 25 on page 4...\n",
      "üëâ Clicking job 26 on page 4...\n",
      "üëâ Clicking job 27 on page 4...\n",
      "üëâ Clicking job 28 on page 4...\n",
      "üëâ Clicking job 29 on page 4...\n",
      "üëâ Clicking job 30 on page 4...\n",
      "üëâ Clicking job 31 on page 4...\n",
      "üëâ Clicking job 32 on page 4...\n",
      "\n",
      "üåê Navigating to Page 5 ‚Äî https://ph.jobstreet.com/Data-Science-jobs?page=5&sortmode=ListedDate\n",
      "üìÑ Found 32 job listings on page 5\n",
      "üëâ Clicking job 1 on page 5...\n",
      "üëâ Clicking job 2 on page 5...\n",
      "üëâ Clicking job 3 on page 5...\n",
      "üëâ Clicking job 4 on page 5...\n",
      "üëâ Clicking job 5 on page 5...\n",
      "üëâ Clicking job 6 on page 5...\n",
      "üëâ Clicking job 7 on page 5...\n",
      "üëâ Clicking job 8 on page 5...\n",
      "üëâ Clicking job 9 on page 5...\n",
      "üëâ Clicking job 10 on page 5...\n",
      "üëâ Clicking job 11 on page 5...\n",
      "üëâ Clicking job 12 on page 5...\n",
      "‚ö†Ô∏è Error on job 12 of page 5: Page.wait_for_selector: Timeout 5000ms exceeded.\n",
      "Call log:\n",
      "  - waiting for locator(\"div[data-automation='jobAdDetails']\") to be visible\n",
      "\n",
      "üëâ Clicking job 13 on page 5...\n",
      "‚ö†Ô∏è Error on job 13 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 14 on page 5...\n",
      "‚ö†Ô∏è Error on job 14 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 15 on page 5...\n",
      "‚ö†Ô∏è Error on job 15 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 16 on page 5...\n",
      "‚ö†Ô∏è Error on job 16 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 17 on page 5...\n",
      "‚ö†Ô∏è Error on job 17 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 18 on page 5...\n",
      "‚ö†Ô∏è Error on job 18 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 19 on page 5...\n",
      "‚ö†Ô∏è Error on job 19 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 20 on page 5...\n",
      "‚ö†Ô∏è Error on job 20 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 21 on page 5...\n",
      "‚ö†Ô∏è Error on job 21 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 22 on page 5...\n",
      "‚ö†Ô∏è Error on job 22 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 23 on page 5...\n",
      "‚ö†Ô∏è Error on job 23 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 24 on page 5...\n",
      "‚ö†Ô∏è Error on job 24 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 25 on page 5...\n",
      "‚ö†Ô∏è Error on job 25 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 26 on page 5...\n",
      "‚ö†Ô∏è Error on job 26 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 27 on page 5...\n",
      "‚ö†Ô∏è Error on job 27 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 28 on page 5...\n",
      "‚ö†Ô∏è Error on job 28 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 29 on page 5...\n",
      "‚ö†Ô∏è Error on job 29 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 30 on page 5...\n",
      "‚ö†Ô∏è Error on job 30 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 31 on page 5...\n",
      "‚ö†Ô∏è Error on job 31 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "üëâ Clicking job 32 on page 5...\n",
      "‚ö†Ô∏è Error on job 32 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "\n",
      "üåê Navigating to Page 6 ‚Äî https://ph.jobstreet.com/Data-Science-jobs?page=6&sortmode=ListedDate\n",
      "üìÑ Found 32 job listings on page 6\n",
      "üëâ Clicking job 1 on page 6...\n",
      "üëâ Clicking job 2 on page 6...\n",
      "üëâ Clicking job 3 on page 6...\n",
      "üëâ Clicking job 4 on page 6...\n",
      "üëâ Clicking job 5 on page 6...\n",
      "üëâ Clicking job 6 on page 6...\n",
      "üëâ Clicking job 7 on page 6...\n",
      "üëâ Clicking job 8 on page 6...\n",
      "üëâ Clicking job 9 on page 6...\n",
      "üëâ Clicking job 10 on page 6...\n",
      "üëâ Clicking job 11 on page 6...\n",
      "üëâ Clicking job 12 on page 6...\n",
      "üëâ Clicking job 13 on page 6...\n",
      "üëâ Clicking job 14 on page 6...\n",
      "üëâ Clicking job 15 on page 6...\n",
      "üëâ Clicking job 16 on page 6...\n",
      "üëâ Clicking job 17 on page 6...\n",
      "üëâ Clicking job 18 on page 6...\n",
      "üëâ Clicking job 19 on page 6...\n",
      "üëâ Clicking job 20 on page 6...\n",
      "üëâ Clicking job 21 on page 6...\n",
      "üëâ Clicking job 22 on page 6...\n",
      "üëâ Clicking job 23 on page 6...\n",
      "üëâ Clicking job 24 on page 6...\n",
      "üëâ Clicking job 25 on page 6...\n",
      "üëâ Clicking job 26 on page 6...\n",
      "üëâ Clicking job 27 on page 6...\n",
      "üëâ Clicking job 28 on page 6...\n",
      "üëâ Clicking job 29 on page 6...\n",
      "üëâ Clicking job 30 on page 6...\n",
      "üëâ Clicking job 31 on page 6...\n",
      "üëâ Clicking job 32 on page 6...\n",
      "\n",
      "üåê Navigating to Page 7 ‚Äî https://ph.jobstreet.com/Data-Science-jobs?page=7&sortmode=ListedDate\n",
      "üìÑ Found 32 job listings on page 7\n",
      "üëâ Clicking job 1 on page 7...\n",
      "üëâ Clicking job 2 on page 7...\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the async function inside Jupyter\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m scrape_jobstreet()\n",
      "Cell \u001b[1;32mIn[76], line 45\u001b[0m, in \u001b[0;36mscrape_jobstreet\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müëâ Clicking job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m job\u001b[38;5;241m.\u001b[39mclick()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m page\u001b[38;5;241m.\u001b[39mwait_for_selector(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv[data-automation=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjobAdDetails\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Extract Job ID from href\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\asyncio\\tasks.py:665\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(delay, result)\u001b[0m\n\u001b[0;32m    661\u001b[0m h \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mcall_later(delay,\n\u001b[0;32m    662\u001b[0m                     futures\u001b[38;5;241m.\u001b[39m_set_result_unless_cancelled,\n\u001b[0;32m    663\u001b[0m                     future, result)\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     h\u001b[38;5;241m.\u001b[39mcancel()\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the async function inside Jupyter\n",
    "run = await scrape_jobstreet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8419536e-0049-4f7d-adb9-2cc10b012726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
