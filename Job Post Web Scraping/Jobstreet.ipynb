{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0402af91-faec-4ed0-9244-27671d2c2b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "080048ea-0965-46d2-917c-720ab7a902f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc1d49b0-5122-44bb-9fca-e92c43f12340",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_jobstreet():\n",
    "    scrape_start_time = datetime.now()\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(\"https://ph.jobstreet.com/Data-Science-jobs?sortmode=ListedDate\")\n",
    "\n",
    "        print(\"🔍 Waiting for job listings to load...\")\n",
    "        await page.wait_for_selector(\"article[data-testid='job-card']\")\n",
    "        await asyncio.sleep(5)  # Ensure full DOM is loaded\n",
    "\n",
    "        jobs = await page.query_selector_all(\"article[data-testid='job-card']\")\n",
    "        print(f\"📄 Found {len(jobs)} job listings\")\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for i, job in enumerate(jobs):\n",
    "            try:\n",
    "                print(f\"👉 Clicking job {i+1}...\")\n",
    "                await job.click()\n",
    "                await asyncio.sleep(2)  # Let right panel populate\n",
    "\n",
    "                # Wait for key detail to appear\n",
    "                await page.wait_for_selector(\"div[data-automation='jobAdDetails']\", timeout=5000)\n",
    "\n",
    "                # Extract job details\n",
    "                job_title_el = await page.query_selector(\"h1[data-automation='job-detail-title']\")\n",
    "                job_title = await job_title_el.inner_text() if job_title_el else \"N/A\"\n",
    "\n",
    "                company_el = await page.query_selector(\"span[data-automation='advertiser-name']\")\n",
    "                company = await company_el.inner_text() if company_el else \"N/A\"\n",
    "\n",
    "                location_el = await page.query_selector(\"span[data-automation='job-detail-location']\")\n",
    "                location = await location_el.inner_text() if location_el else \"N/A\"\n",
    "\n",
    "                work_type_el = await page.query_selector(\"span[data-automation='job-detail-work-type']\")\n",
    "                work_type = await work_type_el.inner_text() if work_type_el else \"N/A\"\n",
    "\n",
    "                classification_el = await page.query_selector(\"span[data-automation='job-detail-classifications']\")\n",
    "                classification = await classification_el.inner_text() if classification_el else \"N/A\"\n",
    "\n",
    "                # Salary: check which one exists\n",
    "                salary_el = await page.query_selector(\"span[data-automation='job-detail-salary']\")\n",
    "                if salary_el:\n",
    "                    salary = await salary_el.inner_text()\n",
    "                else:\n",
    "                    salary = \"\"\n",
    "\n",
    "                # Description block\n",
    "                desc_el = await page.query_selector(\"div[data-automation='jobAdDetails']\")\n",
    "                job_description = await desc_el.inner_text() if desc_el else \"N/A\"\n",
    "\n",
    "                # Job URL from job card element\n",
    "                anchor = await job.query_selector(\"a[data-automation='job-list-view-job-link']\")\n",
    "                url_suffix = await anchor.get_attribute(\"href\") if anchor else \"\"\n",
    "                job_url = \"https://ph.jobstreet.com\" + url_suffix if url_suffix else \"N/A\"\n",
    "\n",
    "                # Posted time from job card\n",
    "                posted_el = await job.query_selector(\"span[data-automation='jobListingDate']\")\n",
    "                posted_raw = await posted_el.inner_text() if posted_el else \"\"\n",
    "                posted_datetime = \"N/A\"\n",
    "                try:\n",
    "                    if \"m\" in posted_raw:\n",
    "                        minutes = int(posted_raw.split(\"m\")[0].strip())\n",
    "                        posted_time = scrape_start_time - timedelta(minutes=minutes)\n",
    "                    elif \"hr\" in posted_raw:\n",
    "                        hours = int(posted_raw.split(\"hr\")[0].strip())\n",
    "                        posted_time = scrape_start_time - timedelta(hours=hours)\n",
    "                    elif \"d\" in posted_raw:\n",
    "                        days = int(posted_raw.split(\"d\")[0].strip())\n",
    "                        posted_time = scrape_start_time - timedelta(days=days)\n",
    "                    else:\n",
    "                        posted_time = scrape_start_time\n",
    "                    posted_datetime = posted_time.strftime(\"%d/%m/%y %H:%M\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Failed to parse posted time '{posted_raw}': {e}\")\n",
    "\n",
    "                data.append({\n",
    "                    \"Job Title\": job_title,\n",
    "                    \"Company\": company,\n",
    "                    \"Location\": location,\n",
    "                    \"Work Type\": work_type,\n",
    "                    \"Classification\": classification,\n",
    "                    \"Salary\": salary,\n",
    "                    \"Job Description\": job_description,\n",
    "                    \"Job URL\": job_url,\n",
    "                    \"Posted Time\": posted_datetime\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error on job {i+1}: {e}\")\n",
    "                continue\n",
    "\n",
    "        await browser.close()\n",
    "        return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8566f40-aaf1-403f-9416-6e40a9f4eb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Waiting for job listings to load...\n",
      "📄 Found 32 job listings\n",
      "👉 Clicking job 1...\n",
      "👉 Clicking job 2...\n",
      "👉 Clicking job 3...\n",
      "👉 Clicking job 4...\n",
      "👉 Clicking job 5...\n",
      "👉 Clicking job 6...\n",
      "👉 Clicking job 7...\n",
      "👉 Clicking job 8...\n",
      "👉 Clicking job 9...\n",
      "👉 Clicking job 10...\n",
      "👉 Clicking job 11...\n",
      "👉 Clicking job 12...\n",
      "👉 Clicking job 13...\n",
      "👉 Clicking job 14...\n",
      "👉 Clicking job 15...\n",
      "👉 Clicking job 16...\n",
      "👉 Clicking job 17...\n",
      "👉 Clicking job 18...\n",
      "👉 Clicking job 19...\n",
      "👉 Clicking job 20...\n",
      "👉 Clicking job 21...\n",
      "👉 Clicking job 22...\n",
      "👉 Clicking job 23...\n",
      "👉 Clicking job 24...\n",
      "👉 Clicking job 25...\n",
      "👉 Clicking job 26...\n",
      "👉 Clicking job 27...\n",
      "👉 Clicking job 28...\n",
      "👉 Clicking job 29...\n",
      "👉 Clicking job 30...\n",
      "👉 Clicking job 31...\n",
      "👉 Clicking job 32...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job URL</th>\n",
       "      <th>Posted Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Integration Specialist</td>\n",
       "      <td>MegaXcess IT Solutions Inc.</td>\n",
       "      <td>Pasig City, Metro Manila (Hybrid)</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Business/Systems Analysts (Information &amp; Commu...</td>\n",
       "      <td></td>\n",
       "      <td>THE OPPORTUNITY:\\n\\nThe Integration Management...</td>\n",
       "      <td>https://ph.jobstreet.com/job/85863081?type=sta...</td>\n",
       "      <td>18/07/25 14:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dev Engineer</td>\n",
       "      <td>OwnBank</td>\n",
       "      <td>Bonifacio Global City, Taguig City, Metro Manila</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Developers/Programmers (Information &amp; Communic...</td>\n",
       "      <td>₱80,000 – ₱120,000 per month</td>\n",
       "      <td>Duties and Responsibilities\\n\\nOversee end-to-...</td>\n",
       "      <td>https://ph.jobstreet.com/job/85863682?type=sta...</td>\n",
       "      <td>18/07/25 14:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Network Engineer</td>\n",
       "      <td>Compass Offices</td>\n",
       "      <td>Taguig City, Metro Manila</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Networks &amp; Systems Administration (Information...</td>\n",
       "      <td></td>\n",
       "      <td>The Network Engineer will be responsible for i...</td>\n",
       "      <td>https://ph.jobstreet.com/job/85863305?type=sta...</td>\n",
       "      <td>18/07/25 14:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jr. SAP Manager</td>\n",
       "      <td>Benby Enterprises, Inc.</td>\n",
       "      <td>Quezon City, Metro Manila</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Management (Information &amp; Communication Techno...</td>\n",
       "      <td></td>\n",
       "      <td>SAP Jr. Manager is responsible in the followin...</td>\n",
       "      <td>https://ph.jobstreet.com/job/85862918?type=sta...</td>\n",
       "      <td>18/07/25 14:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Software Development Lead</td>\n",
       "      <td>Benby Enterprises, Inc.</td>\n",
       "      <td>Quezon City, Metro Manila</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Team Leaders (Information &amp; Communication Tech...</td>\n",
       "      <td></td>\n",
       "      <td>Key Responsibilities:\\n\\nLead and manage all p...</td>\n",
       "      <td>https://ph.jobstreet.com/job/85862630?type=sta...</td>\n",
       "      <td>18/07/25 14:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Job Title                       Company  \\\n",
       "0         Integration Specialist  MegaXcess IT Solutions Inc.    \n",
       "1                   Dev Engineer                      OwnBank    \n",
       "2               Network Engineer              Compass Offices    \n",
       "3                Jr. SAP Manager      Benby Enterprises, Inc.    \n",
       "4  Sr. Software Development Lead      Benby Enterprises, Inc.    \n",
       "\n",
       "                                           Location  Work Type  \\\n",
       "0                 Pasig City, Metro Manila (Hybrid)  Full time   \n",
       "1  Bonifacio Global City, Taguig City, Metro Manila  Full time   \n",
       "2                         Taguig City, Metro Manila  Full time   \n",
       "3                         Quezon City, Metro Manila  Full time   \n",
       "4                         Quezon City, Metro Manila  Full time   \n",
       "\n",
       "                                      Classification  \\\n",
       "0  Business/Systems Analysts (Information & Commu...   \n",
       "1  Developers/Programmers (Information & Communic...   \n",
       "2  Networks & Systems Administration (Information...   \n",
       "3  Management (Information & Communication Techno...   \n",
       "4  Team Leaders (Information & Communication Tech...   \n",
       "\n",
       "                         Salary  \\\n",
       "0                                 \n",
       "1  ₱80,000 – ₱120,000 per month   \n",
       "2                                 \n",
       "3                                 \n",
       "4                                 \n",
       "\n",
       "                                     Job Description  \\\n",
       "0  THE OPPORTUNITY:\\n\\nThe Integration Management...   \n",
       "1  Duties and Responsibilities\\n\\nOversee end-to-...   \n",
       "2  The Network Engineer will be responsible for i...   \n",
       "3  SAP Jr. Manager is responsible in the followin...   \n",
       "4  Key Responsibilities:\\n\\nLead and manage all p...   \n",
       "\n",
       "                                             Job URL     Posted Time  \n",
       "0  https://ph.jobstreet.com/job/85863081?type=sta...  18/07/25 14:43  \n",
       "1  https://ph.jobstreet.com/job/85863682?type=sta...  18/07/25 14:41  \n",
       "2  https://ph.jobstreet.com/job/85863305?type=sta...  18/07/25 14:34  \n",
       "3  https://ph.jobstreet.com/job/85862918?type=sta...  18/07/25 14:27  \n",
       "4  https://ph.jobstreet.com/job/85862630?type=sta...  18/07/25 14:21  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the async function inside Jupyter\n",
    "df = await scrape_jobstreet()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb14d5c8-9088-4793-a2aa-9d58d82bddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"../../Projects-Data/Job-Scraping/Data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97173ddf-6915-430b-b0c0-38641ed60189",
   "metadata": {},
   "source": [
    "# Testing Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4417597-53df-4228-b69a-68dc032803aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from playwright.async_api import async_playwright\n",
    "import os\n",
    "import re\n",
    "\n",
    "async def scrape_jobstreet():\n",
    "    scrape_start_time = datetime.now()\n",
    "    file_path = \"../../Projects-Data/Job-Scraping/Data.xlsx\"\n",
    "\n",
    "    # Load existing data or initialize empty DataFrame\n",
    "    if os.path.exists(file_path):\n",
    "        existing_df = pd.read_excel(file_path)\n",
    "        existing_ids = set(existing_df[\"Job ID\"].dropna().astype(str).unique())\n",
    "    else:\n",
    "        existing_df = pd.DataFrame(columns=[\n",
    "            \"Job Title\", \"Company\", \"Location\", \"Work Type\", \"Classification\",\n",
    "            \"Salary\", \"Job Description\", \"Job ID\", \"Posted Time\"\n",
    "        ])\n",
    "        existing_ids = set()\n",
    "\n",
    "    new_data = []\n",
    "    page_num = 1\n",
    "    stop_scraping = False\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "        page = await browser.new_page()\n",
    "\n",
    "        while not stop_scraping:\n",
    "            url = f\"https://ph.jobstreet.com/Data-Science-jobs?page={page_num}&sortmode=ListedDate\"\n",
    "            print(f\"\\n🌐 Navigating to Page {page_num} — {url}\")\n",
    "            await page.goto(url)\n",
    "            await page.wait_for_selector(\"article[data-testid='job-card']\")\n",
    "            await asyncio.sleep(3)\n",
    "\n",
    "            jobs = await page.query_selector_all(\"article[data-testid='job-card']\")\n",
    "            print(f\"📄 Found {len(jobs)} job listings on page {page_num}\")\n",
    "\n",
    "            for i, job in enumerate(jobs):\n",
    "                try:\n",
    "                    print(f\"👉 Clicking job {i+1} on page {page_num}...\")\n",
    "                    await job.click()\n",
    "                    await asyncio.sleep(2)\n",
    "                    await page.wait_for_selector(\"div[data-automation='jobAdDetails']\", timeout=10000)\n",
    "\n",
    "                    # Extract Job ID from href\n",
    "                    anchor = await job.query_selector(\"a[data-automation='job-list-view-job-link']\")\n",
    "                    url_suffix = await anchor.get_attribute(\"href\") if anchor else \"\"\n",
    "                    match = re.search(r\"/job/(\\d+)\", url_suffix)\n",
    "                    job_id = match.group(1) if match else \"N/A\"\n",
    "\n",
    "                    # 🚨 Stop if duplicate\n",
    "                    if job_id in existing_ids:\n",
    "                        print(f\"🛑 Duplicate job ID '{job_id}' found — stopping.\")\n",
    "                        stop_scraping = True\n",
    "                        break\n",
    "\n",
    "                    # Extract other details\n",
    "                    job_title_el = await page.query_selector(\"h1[data-automation='job-detail-title']\")\n",
    "                    job_title = await job_title_el.inner_text() if job_title_el else \"N/A\"\n",
    "\n",
    "                    company_el = await page.query_selector(\"span[data-automation='advertiser-name']\")\n",
    "                    company = await company_el.inner_text() if company_el else \"N/A\"\n",
    "\n",
    "                    location_el = await page.query_selector(\"span[data-automation='job-detail-location']\")\n",
    "                    location = await location_el.inner_text() if location_el else \"N/A\"\n",
    "\n",
    "                    work_type_el = await page.query_selector(\"span[data-automation='job-detail-work-type']\")\n",
    "                    work_type = await work_type_el.inner_text() if work_type_el else \"N/A\"\n",
    "\n",
    "                    classification_el = await page.query_selector(\"span[data-automation='job-detail-classifications']\")\n",
    "                    classification = await classification_el.inner_text() if classification_el else \"N/A\"\n",
    "\n",
    "                    salary_el = await page.query_selector(\"span[data-automation='job-detail-salary']\")\n",
    "                    salary = await salary_el.inner_text() if salary_el else \"\"\n",
    "\n",
    "                    desc_el = await page.query_selector(\"div[data-automation='jobAdDetails']\")\n",
    "                    job_description = await desc_el.inner_text() if desc_el else \"N/A\"\n",
    "\n",
    "                    posted_el = await job.query_selector(\"span[data-automation='jobListingDate']\")\n",
    "                    posted_raw = await posted_el.inner_text() if posted_el else \"\"\n",
    "                    posted_datetime = \"N/A\"\n",
    "                    try:\n",
    "                        if \"m\" in posted_raw:\n",
    "                            minutes = int(posted_raw.split(\"m\")[0].strip())\n",
    "                            posted_time = scrape_start_time - timedelta(minutes=minutes)\n",
    "                        elif \"hr\" in posted_raw:\n",
    "                            hours = int(posted_raw.split(\"hr\")[0].strip())\n",
    "                            posted_time = scrape_start_time - timedelta(hours=hours)\n",
    "                        elif \"d\" in posted_raw:\n",
    "                            days = int(posted_raw.split(\"d\")[0].strip())\n",
    "                            posted_time = scrape_start_time - timedelta(days=days)\n",
    "                        else:\n",
    "                            posted_time = scrape_start_time\n",
    "                        posted_datetime = posted_time.strftime(\"%d/%m/%y %H:%M\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ Failed to parse posted time '{posted_raw}': {e}\")\n",
    "\n",
    "                    new_data.append({\n",
    "                        \"Job Title\": job_title,\n",
    "                        \"Company\": company,\n",
    "                        \"Location\": location,\n",
    "                        \"Work Type\": work_type,\n",
    "                        \"Classification\": classification,\n",
    "                        \"Salary\": salary,\n",
    "                        \"Job Description\": job_description,\n",
    "                        \"Job ID\": job_id,\n",
    "                        \"Posted Time\": posted_datetime\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error on job {i+1} of page {page_num}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            page_num += 1\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "    # Save to file if there are new jobs\n",
    "    if new_data:\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "        full_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "        full_df.to_excel(file_path, index=False)\n",
    "        print(f\"\\n✅ Scraping finished. {len(new_data)} new job(s) saved to Excel.\")\n",
    "    else:\n",
    "        print(\"\\n📂 No new jobs found to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d44c5a0-82e2-4b41-963b-342e161c37c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌐 Navigating to Page 1 — https://ph.jobstreet.com/Data-Science-jobs?page=1&sortmode=ListedDate\n",
      "📄 Found 32 job listings on page 1\n",
      "👉 Clicking job 1 on page 1...\n",
      "👉 Clicking job 2 on page 1...\n",
      "👉 Clicking job 3 on page 1...\n",
      "👉 Clicking job 4 on page 1...\n",
      "👉 Clicking job 5 on page 1...\n",
      "👉 Clicking job 6 on page 1...\n",
      "👉 Clicking job 7 on page 1...\n",
      "👉 Clicking job 8 on page 1...\n",
      "👉 Clicking job 9 on page 1...\n",
      "👉 Clicking job 10 on page 1...\n",
      "👉 Clicking job 11 on page 1...\n",
      "👉 Clicking job 12 on page 1...\n",
      "👉 Clicking job 13 on page 1...\n",
      "👉 Clicking job 14 on page 1...\n",
      "👉 Clicking job 15 on page 1...\n",
      "👉 Clicking job 16 on page 1...\n",
      "👉 Clicking job 17 on page 1...\n",
      "👉 Clicking job 18 on page 1...\n",
      "👉 Clicking job 19 on page 1...\n",
      "👉 Clicking job 20 on page 1...\n",
      "👉 Clicking job 21 on page 1...\n",
      "👉 Clicking job 22 on page 1...\n",
      "👉 Clicking job 23 on page 1...\n",
      "👉 Clicking job 24 on page 1...\n",
      "👉 Clicking job 25 on page 1...\n",
      "👉 Clicking job 26 on page 1...\n",
      "👉 Clicking job 27 on page 1...\n",
      "👉 Clicking job 28 on page 1...\n",
      "👉 Clicking job 29 on page 1...\n",
      "👉 Clicking job 30 on page 1...\n",
      "👉 Clicking job 31 on page 1...\n",
      "👉 Clicking job 32 on page 1...\n",
      "\n",
      "🌐 Navigating to Page 2 — https://ph.jobstreet.com/Data-Science-jobs?page=2&sortmode=ListedDate\n",
      "📄 Found 32 job listings on page 2\n",
      "👉 Clicking job 1 on page 2...\n",
      "👉 Clicking job 2 on page 2...\n",
      "👉 Clicking job 3 on page 2...\n",
      "👉 Clicking job 4 on page 2...\n",
      "👉 Clicking job 5 on page 2...\n",
      "👉 Clicking job 6 on page 2...\n",
      "👉 Clicking job 7 on page 2...\n",
      "👉 Clicking job 8 on page 2...\n",
      "👉 Clicking job 9 on page 2...\n",
      "👉 Clicking job 10 on page 2...\n",
      "👉 Clicking job 11 on page 2...\n",
      "👉 Clicking job 12 on page 2...\n",
      "👉 Clicking job 13 on page 2...\n",
      "👉 Clicking job 14 on page 2...\n",
      "👉 Clicking job 15 on page 2...\n",
      "👉 Clicking job 16 on page 2...\n",
      "👉 Clicking job 17 on page 2...\n",
      "👉 Clicking job 18 on page 2...\n",
      "👉 Clicking job 19 on page 2...\n",
      "👉 Clicking job 20 on page 2...\n",
      "👉 Clicking job 21 on page 2...\n",
      "👉 Clicking job 22 on page 2...\n",
      "👉 Clicking job 23 on page 2...\n",
      "👉 Clicking job 24 on page 2...\n",
      "👉 Clicking job 25 on page 2...\n",
      "👉 Clicking job 26 on page 2...\n",
      "👉 Clicking job 27 on page 2...\n",
      "👉 Clicking job 28 on page 2...\n",
      "👉 Clicking job 29 on page 2...\n",
      "👉 Clicking job 30 on page 2...\n",
      "👉 Clicking job 31 on page 2...\n",
      "👉 Clicking job 32 on page 2...\n",
      "\n",
      "🌐 Navigating to Page 3 — https://ph.jobstreet.com/Data-Science-jobs?page=3&sortmode=ListedDate\n",
      "📄 Found 32 job listings on page 3\n",
      "👉 Clicking job 1 on page 3...\n",
      "👉 Clicking job 2 on page 3...\n",
      "👉 Clicking job 3 on page 3...\n",
      "👉 Clicking job 4 on page 3...\n",
      "👉 Clicking job 5 on page 3...\n",
      "👉 Clicking job 6 on page 3...\n",
      "👉 Clicking job 7 on page 3...\n",
      "👉 Clicking job 8 on page 3...\n",
      "👉 Clicking job 9 on page 3...\n",
      "👉 Clicking job 10 on page 3...\n",
      "👉 Clicking job 11 on page 3...\n",
      "👉 Clicking job 12 on page 3...\n",
      "👉 Clicking job 13 on page 3...\n",
      "👉 Clicking job 14 on page 3...\n",
      "👉 Clicking job 15 on page 3...\n",
      "👉 Clicking job 16 on page 3...\n",
      "👉 Clicking job 17 on page 3...\n",
      "👉 Clicking job 18 on page 3...\n",
      "👉 Clicking job 19 on page 3...\n",
      "👉 Clicking job 20 on page 3...\n",
      "👉 Clicking job 21 on page 3...\n",
      "👉 Clicking job 22 on page 3...\n",
      "👉 Clicking job 23 on page 3...\n",
      "👉 Clicking job 24 on page 3...\n",
      "👉 Clicking job 25 on page 3...\n",
      "👉 Clicking job 26 on page 3...\n",
      "👉 Clicking job 27 on page 3...\n",
      "👉 Clicking job 28 on page 3...\n",
      "👉 Clicking job 29 on page 3...\n",
      "👉 Clicking job 30 on page 3...\n",
      "👉 Clicking job 31 on page 3...\n",
      "👉 Clicking job 32 on page 3...\n",
      "\n",
      "🌐 Navigating to Page 4 — https://ph.jobstreet.com/Data-Science-jobs?page=4&sortmode=ListedDate\n",
      "📄 Found 32 job listings on page 4\n",
      "👉 Clicking job 1 on page 4...\n",
      "👉 Clicking job 2 on page 4...\n",
      "👉 Clicking job 3 on page 4...\n",
      "👉 Clicking job 4 on page 4...\n",
      "👉 Clicking job 5 on page 4...\n",
      "👉 Clicking job 6 on page 4...\n",
      "👉 Clicking job 7 on page 4...\n",
      "👉 Clicking job 8 on page 4...\n",
      "👉 Clicking job 9 on page 4...\n",
      "👉 Clicking job 10 on page 4...\n",
      "👉 Clicking job 11 on page 4...\n",
      "👉 Clicking job 12 on page 4...\n",
      "👉 Clicking job 13 on page 4...\n",
      "👉 Clicking job 14 on page 4...\n",
      "👉 Clicking job 15 on page 4...\n",
      "👉 Clicking job 16 on page 4...\n",
      "👉 Clicking job 17 on page 4...\n",
      "👉 Clicking job 18 on page 4...\n",
      "👉 Clicking job 19 on page 4...\n",
      "👉 Clicking job 20 on page 4...\n",
      "👉 Clicking job 21 on page 4...\n",
      "👉 Clicking job 22 on page 4...\n",
      "👉 Clicking job 23 on page 4...\n",
      "👉 Clicking job 24 on page 4...\n",
      "👉 Clicking job 25 on page 4...\n",
      "👉 Clicking job 26 on page 4...\n",
      "👉 Clicking job 27 on page 4...\n",
      "👉 Clicking job 28 on page 4...\n",
      "👉 Clicking job 29 on page 4...\n",
      "👉 Clicking job 30 on page 4...\n",
      "👉 Clicking job 31 on page 4...\n",
      "👉 Clicking job 32 on page 4...\n",
      "\n",
      "🌐 Navigating to Page 5 — https://ph.jobstreet.com/Data-Science-jobs?page=5&sortmode=ListedDate\n",
      "📄 Found 32 job listings on page 5\n",
      "👉 Clicking job 1 on page 5...\n",
      "👉 Clicking job 2 on page 5...\n",
      "👉 Clicking job 3 on page 5...\n",
      "👉 Clicking job 4 on page 5...\n",
      "👉 Clicking job 5 on page 5...\n",
      "👉 Clicking job 6 on page 5...\n",
      "👉 Clicking job 7 on page 5...\n",
      "👉 Clicking job 8 on page 5...\n",
      "👉 Clicking job 9 on page 5...\n",
      "👉 Clicking job 10 on page 5...\n",
      "👉 Clicking job 11 on page 5...\n",
      "👉 Clicking job 12 on page 5...\n",
      "⚠️ Error on job 12 of page 5: Page.wait_for_selector: Timeout 5000ms exceeded.\n",
      "Call log:\n",
      "  - waiting for locator(\"div[data-automation='jobAdDetails']\") to be visible\n",
      "\n",
      "👉 Clicking job 13 on page 5...\n",
      "⚠️ Error on job 13 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 14 on page 5...\n",
      "⚠️ Error on job 14 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 15 on page 5...\n",
      "⚠️ Error on job 15 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 16 on page 5...\n",
      "⚠️ Error on job 16 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 17 on page 5...\n",
      "⚠️ Error on job 17 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 18 on page 5...\n",
      "⚠️ Error on job 18 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 19 on page 5...\n",
      "⚠️ Error on job 19 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 20 on page 5...\n",
      "⚠️ Error on job 20 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 21 on page 5...\n",
      "⚠️ Error on job 21 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 22 on page 5...\n",
      "⚠️ Error on job 22 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 23 on page 5...\n",
      "⚠️ Error on job 23 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 24 on page 5...\n",
      "⚠️ Error on job 24 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 25 on page 5...\n",
      "⚠️ Error on job 25 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 26 on page 5...\n",
      "⚠️ Error on job 26 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 27 on page 5...\n",
      "⚠️ Error on job 27 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 28 on page 5...\n",
      "⚠️ Error on job 28 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 29 on page 5...\n",
      "⚠️ Error on job 29 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 30 on page 5...\n",
      "⚠️ Error on job 30 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 31 on page 5...\n",
      "⚠️ Error on job 31 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "👉 Clicking job 32 on page 5...\n",
      "⚠️ Error on job 32 of page 5: ElementHandle.click: Element is not attached to the DOM\n",
      "Call log:\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "\n",
      "\n",
      "🌐 Navigating to Page 6 — https://ph.jobstreet.com/Data-Science-jobs?page=6&sortmode=ListedDate\n",
      "📄 Found 32 job listings on page 6\n",
      "👉 Clicking job 1 on page 6...\n",
      "👉 Clicking job 2 on page 6...\n",
      "👉 Clicking job 3 on page 6...\n",
      "👉 Clicking job 4 on page 6...\n",
      "👉 Clicking job 5 on page 6...\n",
      "👉 Clicking job 6 on page 6...\n",
      "👉 Clicking job 7 on page 6...\n",
      "👉 Clicking job 8 on page 6...\n",
      "👉 Clicking job 9 on page 6...\n",
      "👉 Clicking job 10 on page 6...\n",
      "👉 Clicking job 11 on page 6...\n",
      "👉 Clicking job 12 on page 6...\n",
      "👉 Clicking job 13 on page 6...\n",
      "👉 Clicking job 14 on page 6...\n",
      "👉 Clicking job 15 on page 6...\n",
      "👉 Clicking job 16 on page 6...\n",
      "👉 Clicking job 17 on page 6...\n",
      "👉 Clicking job 18 on page 6...\n",
      "👉 Clicking job 19 on page 6...\n",
      "👉 Clicking job 20 on page 6...\n",
      "👉 Clicking job 21 on page 6...\n",
      "👉 Clicking job 22 on page 6...\n",
      "👉 Clicking job 23 on page 6...\n",
      "👉 Clicking job 24 on page 6...\n",
      "👉 Clicking job 25 on page 6...\n",
      "👉 Clicking job 26 on page 6...\n",
      "👉 Clicking job 27 on page 6...\n",
      "👉 Clicking job 28 on page 6...\n",
      "👉 Clicking job 29 on page 6...\n",
      "👉 Clicking job 30 on page 6...\n",
      "👉 Clicking job 31 on page 6...\n",
      "👉 Clicking job 32 on page 6...\n",
      "\n",
      "🌐 Navigating to Page 7 — https://ph.jobstreet.com/Data-Science-jobs?page=7&sortmode=ListedDate\n",
      "📄 Found 32 job listings on page 7\n",
      "👉 Clicking job 1 on page 7...\n",
      "👉 Clicking job 2 on page 7...\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the async function inside Jupyter\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m scrape_jobstreet()\n",
      "Cell \u001b[1;32mIn[76], line 45\u001b[0m, in \u001b[0;36mscrape_jobstreet\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m👉 Clicking job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m job\u001b[38;5;241m.\u001b[39mclick()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m page\u001b[38;5;241m.\u001b[39mwait_for_selector(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv[data-automation=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjobAdDetails\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Extract Job ID from href\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\asyncio\\tasks.py:665\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(delay, result)\u001b[0m\n\u001b[0;32m    661\u001b[0m h \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mcall_later(delay,\n\u001b[0;32m    662\u001b[0m                     futures\u001b[38;5;241m.\u001b[39m_set_result_unless_cancelled,\n\u001b[0;32m    663\u001b[0m                     future, result)\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     h\u001b[38;5;241m.\u001b[39mcancel()\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the async function inside Jupyter\n",
    "run = await scrape_jobstreet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8419536e-0049-4f7d-adb9-2cc10b012726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
